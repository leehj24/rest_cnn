{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d92b21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd27d00eaf542efaf52f3f1d2a92e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Masks:   0%|          | 0/17851 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료: 17851/17851 masks 생성\n",
      "로그 파일: C:\\Users\\hyunj\\Downloads\\deep_test\\mask\\mask_generation.log\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# ─── 설정 ────────────────────────────────────────────────────\n",
    "image_root = Path(r\"C:\\Users\\hyunj\\Downloads\\deep_test\\gray\")\n",
    "image_subfolders = [\"C_Frontback_D02\", \"C_Frontback_G01\"]\n",
    "\n",
    "ann_root = Path(r\"C:\\Users\\hyunj\\Downloads\\deep_test\\annotation\")\n",
    "\n",
    "output_root = Path(r\"C:\\Users\\hyunj\\Downloads\\deep_test\\mask\")\n",
    "output_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 로그 파일 설정\n",
    "log_file = output_root / \"mask_generation.log\"\n",
    "logging.basicConfig(\n",
    "    filename=log_file,\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\"\n",
    ")\n",
    "\n",
    "# 모폴로지 커널 (크랙 평균 폭에 맞춰 조정 가능)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "\n",
    "# ─── 마스크 생성 함수 ─────────────────────────────────────────\n",
    "def make_mask(pair):\n",
    "    img_path, ann_path = pair\n",
    "    try:\n",
    "        # 1) 이미지 로드\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            raise ValueError(\"이미지 로드 실패\")\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        # 2) 어노테이션 파싱\n",
    "        with open(ann_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # 3) 빈 마스크 초기화\n",
    "        mask = np.zeros((h, w), dtype=np.uint8)\n",
    "\n",
    "        # 4) 중심선 그리기 (thickness=10)\n",
    "        for obj in data.get(\"annotations\", []):\n",
    "            for poly in obj.get(\"polyline\", []):\n",
    "                pts = np.array(poly, dtype=np.float32).reshape(-1, 2)\n",
    "                pts = np.round(pts).astype(np.int32)\n",
    "                cv2.polylines(mask, [pts], isClosed=False, color=255, thickness=10)\n",
    "\n",
    "        # 5) 모폴로지 팽창으로 폭 확대\n",
    "        mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "\n",
    "        # 6) 마스크 저장 (원본 하위 폴더 구조 유지)\n",
    "        out_dir = output_root / img_path.parent.name\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        out_path = out_dir / f\"{img_path.stem}_mask.png\"\n",
    "        cv2.imwrite(str(out_path), mask)\n",
    "\n",
    "        return True, str(img_path)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"{img_path} 실패: {e}\")\n",
    "        return False, str(img_path)\n",
    "\n",
    "# ─── 입력 쌍 수집 ────────────────────────────────────────────\n",
    "pairs = []\n",
    "for sub in image_subfolders:\n",
    "    img_dir = image_root / sub\n",
    "    ann_dir = ann_root / sub\n",
    "    for img_path in img_dir.glob(\"*.webp\"):\n",
    "        ann_path = ann_dir / f\"{img_path.stem}_PLINE.json\"\n",
    "        if ann_path.exists():\n",
    "            pairs.append((img_path, ann_path))\n",
    "        else:\n",
    "            logging.warning(f\"어노테이션 없음: {img_path}\")\n",
    "\n",
    "# ─── 멀티스레드 병렬 처리 ────────────────────────────────────\n",
    "workers = min(len(pairs), os.cpu_count() or 1)\n",
    "success_count = 0\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=workers) as executor:\n",
    "    futures = [executor.submit(make_mask, p) for p in pairs]\n",
    "    for future in tqdm(as_completed(futures),\n",
    "                       total=len(futures),\n",
    "                       desc=\"Generating Masks\"):\n",
    "        ok, _ = future.result()\n",
    "        if ok:\n",
    "            success_count += 1\n",
    "\n",
    "print(f\"완료: {success_count}/{len(pairs)} masks 생성\")\n",
    "print(f\"로그 파일: {log_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12d3823f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8 Segmentation용 .txt 파일 생성 완료!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# ─── 설정 ────────────────────────────────────────────────────\n",
    "mask_root = r\"C:\\Users\\hyunj\\Downloads\\deep_test\\mask\"\n",
    "image_subfolders = [\"C_Frontback_D02\", \"C_Frontback_G01\"]\n",
    "\n",
    "output_txt_root = r\"C:\\Users\\hyunj\\Downloads\\deep_test\\txt\"\n",
    "os.makedirs(output_txt_root, exist_ok=True)\n",
    "\n",
    "# ─── 모든 서브폴더 순회 ─────────────────────────────────────────\n",
    "for sub in image_subfolders:\n",
    "    mask_folder = os.path.join(mask_root, sub)\n",
    "    output_txt_folder = os.path.join(output_txt_root, sub)\n",
    "    os.makedirs(output_txt_folder, exist_ok=True)\n",
    "\n",
    "    if not os.path.isdir(mask_folder):\n",
    "        print(f\"경고: 해당 폴더가 없습니다: {mask_folder}\")\n",
    "        continue\n",
    "\n",
    "    for filename in os.listdir(mask_folder):\n",
    "        if not filename.lower().endswith(\".png\"):\n",
    "            continue\n",
    "\n",
    "        mask_path = os.path.join(mask_folder, filename)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            print(f\"이미지 로드 실패: {mask_path}\")\n",
    "            continue\n",
    "\n",
    "        height, width = mask.shape[:2]\n",
    "\n",
    "        # 윤곽선 찾기 (CHAIN_APPROX_NONE으로 더 세밀하게)\n",
    "        contours, _ = cv2.findContours(\n",
    "            mask,\n",
    "            cv2.RETR_EXTERNAL,\n",
    "            cv2.CHAIN_APPROX_NONE\n",
    "        )\n",
    "\n",
    "        txt_lines = []\n",
    "        for contour in contours:\n",
    "            if len(contour) < 3:\n",
    "                continue  # 폴리곤은 최소 3점 필요\n",
    "\n",
    "            # 정규화된 좌표 생성\n",
    "            coords = []\n",
    "            for pt in contour:\n",
    "                x, y = pt[0]\n",
    "                coords.append(f\"{x/width:.6f} {y/height:.6f}\")\n",
    "\n",
    "            # YOLO Seg 파일 포맷\n",
    "            class_id = 0\n",
    "            txt_lines.append(f\"{class_id} \" + \" \".join(coords))\n",
    "\n",
    "        # TXT 저장\n",
    "        txt_filename = filename.rsplit(\".\", 1)[0] + \".txt\"\n",
    "        txt_path = os.path.join(output_txt_folder, txt_filename)\n",
    "        with open(txt_path, \"w\") as f:\n",
    "            f.write(\"\\n\".join(txt_lines))\n",
    "\n",
    "print(\"YOLOv8 Segmentation용 .txt 파일 생성 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2c8e29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8 Segmentation용 approxPolyDP 기반 .txt 생성 완료!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "BASE = Path(r\"C:\\Users\\hyunj\\Downloads\\deep_test\")\n",
    "# ─── 설정 ────────────────────────────────────────────────────\n",
    "mask_root = r\"C:\\Users\\hyunj\\Downloads\\deep_test\\gray\"\n",
    "image_subfolders = [\"C_Frontback_D02\", \"C_Frontback_G01\"]\n",
    "\n",
    "output_txt_root = r\"C:\\Users\\hyunj\\Downloads\\deep_test\\txt_approx\"\n",
    "os.makedirs(output_txt_root, exist_ok=True)\n",
    "\n",
    "mlruns_dir = BASE / \"mlruns\"\n",
    "mlruns_dir.mkdir(exist_ok=True)\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = f\"file:///{mlruns_dir.as_posix()}\"\n",
    "\n",
    "\n",
    "# ─── 모든 서브폴더 순회 ─────────────────────────────────────────\n",
    "for sub in image_subfolders:\n",
    "    mask_folder = os.path.join(mask_root, sub)\n",
    "    output_txt_folder = os.path.join(output_txt_root, sub)\n",
    "    os.makedirs(output_txt_folder, exist_ok=True)\n",
    "\n",
    "    if not os.path.isdir(mask_folder):\n",
    "        print(f\"경고: 해당 폴더가 없습니다: {mask_folder}\")\n",
    "        continue\n",
    "\n",
    "    for filename in os.listdir(mask_folder):\n",
    "        if not filename.lower().endswith(\".png\"):\n",
    "            continue\n",
    "\n",
    "        mask_path = os.path.join(mask_folder, filename)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            print(f\"이미지 로드 실패: {mask_path}\")\n",
    "            continue\n",
    "\n",
    "        height, width = mask.shape[:2]\n",
    "\n",
    "        # 윤곽선 찾기 (모든 점을 추출)\n",
    "        contours, _ = cv2.findContours(\n",
    "            mask,\n",
    "            cv2.RETR_EXTERNAL,\n",
    "            cv2.CHAIN_APPROX_NONE\n",
    "        )\n",
    "\n",
    "        txt_lines = []\n",
    "        for contour in contours:\n",
    "            if len(contour) < 3:\n",
    "                continue  # 폴리곤은 최소 3점 필요\n",
    "\n",
    "            # approxPolyDP로 단순화\n",
    "            epsilon = 0.005 * cv2.arcLength(contour, True)  # 이 값을 조절하며 점 개수 조절 가능\n",
    "            simplified = cv2.approxPolyDP(contour, epsilon, True)\n",
    "            if len(simplified) < 3:\n",
    "                continue\n",
    "\n",
    "            # 정규화된 좌표 생성\n",
    "            coords = []\n",
    "            for pt in simplified:\n",
    "                x, y = pt[0]\n",
    "                coords.append(f\"{x/width:.6f} {y/height:.6f}\")\n",
    "\n",
    "            # YOLO Seg 포맷: class_id + 좌표들\n",
    "            class_id = 0\n",
    "            txt_lines.append(f\"{class_id} \" + \" \".join(coords))\n",
    "\n",
    "        # TXT 저장\n",
    "        txt_filename = os.path.splitext(filename)[0] + \".txt\"\n",
    "        txt_path = os.path.join(output_txt_folder, txt_filename)\n",
    "        with open(txt_path, \"w\") as f:\n",
    "            f.write(\"\\n\".join(txt_lines))\n",
    "\n",
    "print(\"YOLOv8 Segmentation용 approxPolyDP 기반 .txt 생성 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47133774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ 데이터 분할 및 복사 완료\n",
      "✔️ data.yaml 작성 완료\n",
      "New https://pypi.org/project/ultralytics/8.3.145 available  Update with 'pip install -U ultralytics'\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'\u001b[31m\u001b[1mlog_mlflow\u001b[0m' is not a valid YOLO argument. \n\n    Arguments received: ['yolo', '--f=c:\\\\Users\\\\hyunj\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v3978bf20d1db1cc37962144e1869a925fc8e57e51.json']. Ultralytics 'yolo' commands use the following syntax:\n\n        yolo TASK MODE ARGS\n\n        Where   TASK (optional) is one of frozenset({'obb', 'classify', 'pose', 'detect', 'segment'})\n                MODE (required) is one of frozenset({'val', 'train', 'benchmark', 'track', 'predict', 'export'})\n                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n\n    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n        yolo train data=coco8.yaml model=yolo11n.pt epochs=10 lr0=0.01\n\n    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n        yolo predict model=yolo11n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n\n    3. Val a pretrained detection model at batch-size 1 and image size 640:\n        yolo val model=yolo11n.pt data=coco8.yaml batch=1 imgsz=640\n\n    4. Export a YOLO11n classification model to ONNX format at image size 224 by 128 (no TASK required)\n        yolo export model=yolo11n-cls.pt format=onnx imgsz=224,128\n\n    5. Ultralytics solutions usage\n        yolo solutions count or in ['crop', 'blur', 'workout', 'heatmap', 'isegment', 'visioneye', 'speed', 'queue', 'analytics', 'inference', 'trackzone'] source=\"path/to/video.mp4\"\n\n    6. Run special commands:\n        yolo help\n        yolo checks\n        yolo version\n        yolo settings\n        yolo copy-cfg\n        yolo cfg\n        yolo solutions help\n\n    Docs: https://docs.ultralytics.com\n    Solutions: https://docs.ultralytics.com/solutions/\n    Community: https://community.ultralytics.com\n    GitHub: https://github.com/ultralytics/ultralytics\n     (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:3550\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[13], line 83\u001b[0m\n    model.train(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\ultralytics\\engine\\model.py:787\u001b[0m in \u001b[0;35mtrain\u001b[0m\n    self.trainer = (trainer or self._smart_load(\"trainer\"))(overrides=args, _callbacks=self.callbacks)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\ultralytics\\models\\yolo\\segment\\train.py:49\u001b[0m in \u001b[0;35m__init__\u001b[0m\n    super().__init__(cfg, overrides, _callbacks)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\ultralytics\\engine\\trainer.py:103\u001b[0m in \u001b[0;35m__init__\u001b[0m\n    self.args = get_cfg(cfg, overrides)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\ultralytics\\cfg\\__init__.py:306\u001b[0m in \u001b[0;35mget_cfg\u001b[0m\n    check_dict_alignment(cfg, overrides)\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\ultralytics\\cfg\\__init__.py:496\u001b[1;36m in \u001b[1;35mcheck_dict_alignment\u001b[1;36m\n\u001b[1;33m    raise SyntaxError(string + CLI_HELP_MSG) from e\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m<string>\u001b[1;36m\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m '\u001b[31m\u001b[1mlog_mlflow\u001b[0m' is not a valid YOLO argument. \n\n    Arguments received: ['yolo', '--f=c:\\\\Users\\\\hyunj\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v3978bf20d1db1cc37962144e1869a925fc8e57e51.json']. Ultralytics 'yolo' commands use the following syntax:\n\n        yolo TASK MODE ARGS\n\n        Where   TASK (optional) is one of frozenset({'obb', 'classify', 'pose', 'detect', 'segment'})\n                MODE (required) is one of frozenset({'val', 'train', 'benchmark', 'track', 'predict', 'export'})\n                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n\n    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n        yolo train data=coco8.yaml model=yolo11n.pt epochs=10 lr0=0.01\n\n    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n        yolo predict model=yolo11n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n\n    3. Val a pretrained detection model at batch-size 1 and image size 640:\n        yolo val model=yolo11n.pt data=coco8.yaml batch=1 imgsz=640\n\n    4. Export a YOLO11n classification model to ONNX format at image size 224 by 128 (no TASK required)\n        yolo export model=yolo11n-cls.pt format=onnx imgsz=224,128\n\n    5. Ultralytics solutions usage\n        yolo solutions count or in ['crop', 'blur', 'workout', 'heatmap', 'isegment', 'visioneye', 'speed', 'queue', 'analytics', 'inference', 'trackzone'] source=\"path/to/video.mp4\"\n\n    6. Run special commands:\n        yolo help\n        yolo checks\n        yolo version\n        yolo settings\n        yolo copy-cfg\n        yolo cfg\n        yolo solutions help\n\n    Docs: https://docs.ultralytics.com\n    Solutions: https://docs.ultralytics.com/solutions/\n    Community: https://community.ultralytics.com\n    GitHub: https://github.com/ultralytics/ultralytics\n    \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ultralytics import YOLO\n",
    "import yaml\n",
    "\n",
    "# ─── 1) 경로 설정 ──────────────────────────────────────────────\n",
    "BASE         = Path(r\"C:\\Users\\hyunj\\Downloads\\deep_test\")\n",
    "images_root  = BASE / \"gray\"    # 원본 이미지(.webp 혹은 .png)\n",
    "labels_root  = BASE / \"txt\"     # YOLO Seg .txt (서브폴더별로 _mask.txt 로 저장됨)\n",
    "subfolders   = [\"C_Frontback_D02\", \"C_Frontback_G01\"]\n",
    "\n",
    "mlruns_dir = BASE / \"mlruns\"\n",
    "mlruns_dir.mkdir(exist_ok=True)\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = f\"file:///{mlruns_dir.as_posix()}\"\n",
    "\n",
    "# ─── 2) 분할된 데이터 저장 구조 ─────────────────────────────────\n",
    "out_base     = BASE / \"dataset\"\n",
    "train_images = out_base / \"images\" / \"train\"\n",
    "val_images   = out_base / \"images\" / \"val\"\n",
    "train_labels = out_base / \"labels\" / \"train\"\n",
    "val_labels   = out_base / \"labels\" / \"val\"\n",
    "for d in (train_images, val_images, train_labels, val_labels):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ─── 3) train/val 분할 & 복사 ──────────────────────────────────\n",
    "for sub in subfolders:\n",
    "    img_dir = images_root / sub\n",
    "    lbl_dir = labels_root / sub\n",
    "\n",
    "    if not img_dir.exists():\n",
    "        print(f\"[경고] 이미지 폴더가 없습니다: {img_dir}\")\n",
    "        continue\n",
    "    if not lbl_dir.exists():\n",
    "        print(f\"[경고] 라벨 폴더가 없습니다: {lbl_dir}\")\n",
    "        continue\n",
    "\n",
    "    # 이미지 목록(.webp, .png)\n",
    "    imgs = list(img_dir.glob(\"*.webp\")) + list(img_dir.glob(\"*.png\"))\n",
    "    train_imgs, val_imgs = train_test_split(imgs, test_size=0.2, random_state=42)\n",
    "\n",
    "    for split, img_list in [(\"train\", train_imgs), (\"val\", val_imgs)]:\n",
    "        for img_path in img_list:\n",
    "            # 1) 이미지 복사\n",
    "            dst_img_dir = (train_images if split==\"train\" else val_images) / sub\n",
    "            dst_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.copy(img_path, dst_img_dir / img_path.name)\n",
    "\n",
    "            # 2) 라벨(.txt) 복사\n",
    "            #   (1) img_path.stem + \".txt\"\n",
    "            #   (2) img_path.stem + \"_mask.txt\"  두 가지 경우 모두 확인\n",
    "            candidates = [\n",
    "                lbl_dir / f\"{img_path.stem}.txt\",\n",
    "                lbl_dir / f\"{img_path.stem}_mask.txt\"\n",
    "            ]\n",
    "            found = False\n",
    "            for lbl_path in candidates:\n",
    "                if lbl_path.exists():\n",
    "                    dst_lbl_dir = (train_labels if split==\"train\" else val_labels) / sub\n",
    "                    dst_lbl_dir.mkdir(parents=True, exist_ok=True)\n",
    "                    shutil.copy(lbl_path, dst_lbl_dir / lbl_path.name)\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                print(f\"[경고] 라벨 파일을 찾을 수 없음: {candidates}\")\n",
    "\n",
    "print(\"✔️ 데이터 분할 및 복사 완료\")\n",
    "\n",
    "# ─── 4) data.yaml 생성 ─────────────────────────────────────────\n",
    "data_yaml = {\n",
    "    \"train\": str(train_images.parent),  # dataset/images\n",
    "    \"val\":   str(val_images.parent),\n",
    "    \"nc\": 1,\n",
    "    \"names\": [\"crack\"]\n",
    "}\n",
    "with open(BASE / \"data.yaml\", \"w\") as f:\n",
    "    yaml.dump(data_yaml, f, sort_keys=False)\n",
    "print(\"✔️ data.yaml 작성 완료\")\n",
    "\n",
    "# ─── 5) YOLOv8 세그멘테이션 학습 ───────────────────────────────\n",
    "model = YOLO(\"yolov8n-seg.pt\")\n",
    "model.train(\n",
    "    data=str(BASE / \"data.yaml\"),\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=8,\n",
    "    name=\"crack_segmentation\",\n",
    "    val=False,            # ← 검증 생략\n",
    "    log_mlflow=False      # (이전 MLflow 에러 방지를 위해 여전히 꺼둘 수 있습니다)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80306c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.145 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.137  Python-3.9.21 torch-2.7.0+cu128 CPU (11th Gen Intel Core(TM) i7-11700 2.50GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:/Users/hyunj/Downloads/deep_test/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=crack_segmentation7, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=e:\\runs\\segment\\crack_segmentation7, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   1004275  ultralytics.nn.modules.head.Segment          [1, 32, 64, [64, 128, 256]]   \n",
      "YOLOv8n-seg summary: 151 layers, 3,263,811 parameters, 3,263,795 gradients, 12.1 GFLOPs\n",
      "\n",
      "Transferred 381/417 items from pretrained weights\n",
      "WARNING ClearML installed but not initialized correctly, not logging this run. It seems ClearML is not configured on this machine!\n",
      "To get started with ClearML, setup your own 'clearml-server' or create a free account at https://app.clear.ml\n",
      "Setup instructions can be found here: https://clear.ml/docs\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 904.3213.0 MB/s, size: 165.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\labels\\train\\C_Frontback_D02.cache... 0 images, 14265 backgrounds, 15 corrupt: 100%|██████████| 14280/14280 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_0898_20201231_111555_E_CH0_Seoul_Sun_Frontback_Day_88937.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_2899_20201109_093348_N_CH2_Seoul_Sun_Frontback_Day_04037.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_4471_20201230_122847_E_CH0_Seoul_Sun_Frontback_Day_83952.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_5502_20201224_104609_N_CH1_Seoul_Sun_Frontback_Sunrise_40987.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_6015_20201109_094048_N_CH2_Seoul_Sun_Frontback_Day_59877.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_6054_20201231_111555_E_CH1_Seoul_Sun_Frontback_Day_64387.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_6428_20201109_093048_E_CH0_Seoul_Sun_Frontback_Day_80356.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_7516_20201229_171815_N_CH0_Seoul_Sun_Frontback_Sunset_95390.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_7636_20201109_093348_E_CH2_Seoul_Sun_Frontback_Day_99127.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_9158_20201102_113908_E_CH0_Seoul_Sun_Frontback_Day_55738.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_9601_20201109_093348_E_CH1_Seoul_Sun_Frontback_Day_81018.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_9694_20201109_093848_N_CH0_Seoul_Sun_Frontback_Day_15771.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V3F_HY_0637_20201102_134232_E_CH0_Seoul_Sun_Frontback_Day_90729.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V3F_HY_1050_20201102_134032_E_CH1_Seoul_Sun_Frontback_Day_69335.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V3F_HY_5009_20160212_023050_N_CH1_Seoul_Sun_Frontback_Day_33344.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "WARNING Labels are missing or empty in C:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\labels\\train\\C_Frontback_D02.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 882.9155.6 MB/s, size: 162.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\labels\\val\\C_Frontback_D02.cache... 0 images, 3567 backgrounds, 4 corrupt: 100%|██████████| 3571/3571 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\val\\C_Frontback_G01\\V2F_HY_3674_20201230_150636_N_CH0_Seoul_Sun_Frontback_Day_74627.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\val\\C_Frontback_G01\\V2F_HY_8030_20201231_111555_E_CH0_Seoul_Sun_Frontback_Day_86195.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\val\\C_Frontback_G01\\V3F_HY_1181_20160212_023749_E_CH1_Seoul_Sun_Frontback_Sunset_86619.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\val\\C_Frontback_G01\\V3F_HY_1347_20160212_022303_N_CH0_Seoul_Sun_Frontback_Day_76884.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "WARNING Labels are missing or empty in C:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\labels\\val\\C_Frontback_D02.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "Plotting labels to e:\\runs\\segment\\crack_segmentation7\\labels.jpg... \n",
      "WARNING zero-size array to reduction operation maximum which has no identity\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "2025/05/26 18:19:50 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
      "2025/05/26 18:19:50 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mMLflow: \u001b[0mlogging run_id(6ba2cb696d5c4b209b958933177f5143) to file:///C:/Users/hyunj/Downloads/deep_test/mlruns\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1me:\\runs\\segment\\crack_segmentation7\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50         0G          0          0      4.426          0          0        640: 100%|██████████| 1784/1784 [1:27:40<00:00,  2.95s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 223/223 [05:27<00:00,  1.47s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "torch.cat(): expected a non-empty list of Tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov8n-seg.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# 2) 학습 실행\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:/Users/hyunj/Downloads/deep_test/data.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcrack_segmentation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     21\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m학습이 완료되었습니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\ultralytics\\engine\\model.py:793\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m    792\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 793\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\ultralytics\\engine\\trainer.py:211\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    208\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\ultralytics\\engine\\trainer.py:443\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;66;03m# Validation\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mval \u001b[38;5;129;01mor\u001b[39;00m final_epoch \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopper\u001b[38;5;241m.\u001b[39mpossible_stop \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop:\n\u001b[1;32m--> 443\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_metrics(metrics\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_loss_items(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr})\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopper(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness) \u001b[38;5;129;01mor\u001b[39;00m final_epoch\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\ultralytics\\engine\\trainer.py:639\u001b[0m, in \u001b[0;36mBaseTrainer.validate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    633\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;124;03m    Run validation on test set using self.validator.\u001b[39;00m\n\u001b[0;32m    635\u001b[0m \n\u001b[0;32m    636\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;124;03m        (tuple): A tuple containing metrics dictionary and fitness score.\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 639\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    640\u001b[0m     fitness \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())  \u001b[38;5;66;03m# use loss as fitness measure if not found\u001b[39;00m\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_fitness \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_fitness \u001b[38;5;241m<\u001b[39m fitness:\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\ultralytics\\engine\\validator.py:231\u001b[0m, in \u001b[0;36mBaseValidator.__call__\u001b[1;34m(self, trainer, model)\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_predictions(batch, preds, batch_i)\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_val_batch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 231\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_stats(stats)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspeed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspeed\u001b[38;5;241m.\u001b[39mkeys(), (x\u001b[38;5;241m.\u001b[39mt \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader\u001b[38;5;241m.\u001b[39mdataset) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1e3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m dt)))\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\ultralytics\\models\\yolo\\detect\\val.py:247\u001b[0m, in \u001b[0;36mDetectionValidator.get_stats\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_stats\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    241\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03m    Calculate and return metrics statistics.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m        (dict): Dictionary containing metrics results.\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m     stats \u001b[38;5;241m=\u001b[39m {k: torch\u001b[38;5;241m.\u001b[39mcat(v, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mitems()}  \u001b[38;5;66;03m# to numpy\u001b[39;00m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnt_per_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_cls\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m), minlength\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnc)\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnt_per_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_img\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m), minlength\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnc)\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\ultralytics\\models\\yolo\\detect\\val.py:247\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_stats\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    241\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03m    Calculate and return metrics statistics.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m        (dict): Dictionary containing metrics results.\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m     stats \u001b[38;5;241m=\u001b[39m {k: \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mitems()}  \u001b[38;5;66;03m# to numpy\u001b[39;00m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnt_per_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_cls\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m), minlength\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnc)\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnt_per_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_img\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m), minlength\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnc)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: torch.cat(): expected a non-empty list of Tensors"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 0) MLflow Tracking URI를 올바른 파일 URI로 설정\n",
    "#    - \"file:///\" + 드라이브+경로\n",
    "mlruns = r\"C:\\Users\\hyunj\\Downloads\\deep_test\\mlruns\"\n",
    "os.makedirs(mlruns, exist_ok=True)\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = f\"file:///{mlruns.replace(os.sep, '/')}\"\n",
    "\n",
    "# 1) 모델 로드\n",
    "model = YOLO(\"yolov8n-seg.pt\")\n",
    "\n",
    "# 2) 학습 실행\n",
    "model.train(\n",
    "    data=\"C:/Users/hyunj/Downloads/deep_test/data.yaml\",\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=8,\n",
    "    name=\"crack_segmentation\",\n",
    "    val=True\n",
    ")\n",
    "\n",
    "print(\"학습이 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "465e8944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[subfolder: C_Frontback_D02]\n",
      " Images exist: True -> 8531\n",
      "  *.webp files: 8531\n",
      "  *.png   files: 0\n",
      "Labels exist: True -> 8531\n",
      "  *.txt   files: 8531\n",
      "\n",
      "[subfolder: C_Frontback_G01]\n",
      " Images exist: True -> 9320\n",
      "  *.webp files: 9320\n",
      "  *.png   files: 0\n",
      "Labels exist: True -> 9320\n",
      "  *.txt   files: 9320\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "base_out    = Path(r\"C:\\Users\\hyunj\\Downloads\\deep_test\")\n",
    "image_root  = base_out / \"gray\"\n",
    "seg_txt     = base_out / \"txt\"\n",
    "subfolders  = [\"C_Frontback_D02\", \"C_Frontback_G01\"]\n",
    "\n",
    "for sub in subfolders:\n",
    "    img_dir = image_root / sub\n",
    "    txt_dir = seg_txt    / sub\n",
    "    print(f\"\\n[subfolder: {sub}]\")\n",
    "    print(\" Images exist:\", img_dir.exists(), \"->\", len(list(img_dir.iterdir())) if img_dir.exists() else 0)\n",
    "    print(\"  *.webp files:\", len(list(img_dir.glob(\"*.webp\"))))\n",
    "    print(\"  *.png   files:\", len(list(img_dir.glob(\"*.png\"))))\n",
    "    print(\"Labels exist:\", txt_dir.exists(), \"->\", len(list(txt_dir.iterdir())) if txt_dir.exists() else 0)\n",
    "    print(\"  *.txt   files:\", len(list(txt_dir.glob(\"*.txt\"))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "866929fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 전체 파일 쌍: 17851\n",
      "train: 14280 쌍, val: 3571 쌍\n",
      "✅ train/val 파일 복사 완료\n",
      "✅ data.yaml 생성: C:\\Users\\hyunj\\Downloads\\deep_test\\crack_segmentation2.yaml\n",
      "New https://pypi.org/project/ultralytics/8.3.145 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.137  Python-3.9.21 torch-2.7.0+cu128 CPU (11th Gen Intel Core(TM) i7-11700 2.50GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:/Users/hyunj/Downloads/deep_test/crack_segmentation2.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=crack_seg2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:/Users/hyunj/Downloads/deep_test/yolo_results, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\hyunj\\Downloads\\deep_test\\yolo_results\\crack_seg2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   1004275  ultralytics.nn.modules.head.Segment          [1, 32, 64, [64, 128, 256]]   \n",
      "YOLOv8n-seg summary: 151 layers, 3,263,811 parameters, 3,263,795 gradients, 12.1 GFLOPs\n",
      "\n",
      "Transferred 381/417 items from pretrained weights\n",
      "WARNING ClearML installed but not initialized correctly, not logging this run. It seems ClearML is not configured on this machine!\n",
      "To get started with ClearML, setup your own 'clearml-server' or create a free account at https://app.clear.ml\n",
      "Setup instructions can be found here: https://clear.ml/docs\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 13.13.6 MB/s, size: 148.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\labels\\train\\C_Frontback_D02... 0 images, 28529 backgrounds, 31 corrupt: 100%|██████████| 28560/28560 [00:52<00:00, 545.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_0898_20201231_111555_E_CH0_Seoul_Sun_Frontback_Day_88937.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_2899_20201109_093348_N_CH2_Seoul_Sun_Frontback_Day_04037.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_4471_20201230_122847_E_CH0_Seoul_Sun_Frontback_Day_83952.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_5502_20201224_104609_N_CH1_Seoul_Sun_Frontback_Sunrise_40987.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_6015_20201109_094048_N_CH2_Seoul_Sun_Frontback_Day_59877.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_6054_20201231_111555_E_CH1_Seoul_Sun_Frontback_Day_64387.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_6428_20201109_093048_E_CH0_Seoul_Sun_Frontback_Day_80356.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_7516_20201229_171815_N_CH0_Seoul_Sun_Frontback_Sunset_95390.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_7636_20201109_093348_E_CH2_Seoul_Sun_Frontback_Day_99127.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_9158_20201102_113908_E_CH0_Seoul_Sun_Frontback_Day_55738.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_9601_20201109_093348_E_CH1_Seoul_Sun_Frontback_Day_81018.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_9694_20201109_093848_N_CH0_Seoul_Sun_Frontback_Day_15771.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V3F_HY_0637_20201102_134232_E_CH0_Seoul_Sun_Frontback_Day_90729.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V3F_HY_1050_20201102_134032_E_CH1_Seoul_Sun_Frontback_Day_69335.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V3F_HY_5009_20160212_023050_N_CH1_Seoul_Sun_Frontback_Day_33344.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_0898_20201231_111555_E_CH0_Seoul_Sun_Frontback_Day_88937.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_2899_20201109_093348_N_CH2_Seoul_Sun_Frontback_Day_04037.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_3674_20201230_150636_N_CH0_Seoul_Sun_Frontback_Day_74627.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_4471_20201230_122847_E_CH0_Seoul_Sun_Frontback_Day_83952.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_5502_20201224_104609_N_CH1_Seoul_Sun_Frontback_Sunrise_40987.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_6015_20201109_094048_N_CH2_Seoul_Sun_Frontback_Day_59877.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_6054_20201231_111555_E_CH1_Seoul_Sun_Frontback_Day_64387.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_7516_20201229_171815_N_CH0_Seoul_Sun_Frontback_Sunset_95390.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_7636_20201109_093348_E_CH2_Seoul_Sun_Frontback_Day_99127.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_8030_20201231_111555_E_CH0_Seoul_Sun_Frontback_Day_86195.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_9158_20201102_113908_E_CH0_Seoul_Sun_Frontback_Day_55738.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_9601_20201109_093348_E_CH1_Seoul_Sun_Frontback_Day_81018.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V3F_HY_0637_20201102_134232_E_CH0_Seoul_Sun_Frontback_Day_90729.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V3F_HY_1050_20201102_134032_E_CH1_Seoul_Sun_Frontback_Day_69335.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V3F_HY_1347_20160212_022303_N_CH0_Seoul_Sun_Frontback_Day_76884.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V3F_HY_5009_20160212_023050_N_CH1_Seoul_Sun_Frontback_Day_33344.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "WARNING \u001b[34m\u001b[1mtrain: \u001b[0mNo labels found in C:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\labels\\train\\C_Frontback_D02.cache. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\labels\\train\\C_Frontback_D02.cache\n",
      "WARNING Labels are missing or empty in C:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\labels\\train\\C_Frontback_D02.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 21.35.3 MB/s, size: 149.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\labels\\val\\C_Frontback_D02... 0 images, 7135 backgrounds, 7 corrupt: 100%|██████████| 7142/7142 [00:12<00:00, 584.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\val\\C_Frontback_G01\\V2F_HY_3674_20201230_150636_N_CH0_Seoul_Sun_Frontback_Day_74627.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\val\\C_Frontback_G01\\V2F_HY_8030_20201231_111555_E_CH0_Seoul_Sun_Frontback_Day_86195.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\val\\C_Frontback_G01\\V3F_HY_1181_20160212_023749_E_CH1_Seoul_Sun_Frontback_Sunset_86619.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\val\\C_Frontback_G01\\V3F_HY_1347_20160212_022303_N_CH0_Seoul_Sun_Frontback_Day_76884.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\val\\C_Frontback_G01_V2F_HY_6428_20201109_093048_E_CH0_Seoul_Sun_Frontback_Day_80356.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\val\\C_Frontback_G01_V2F_HY_9694_20201109_093848_N_CH0_Seoul_Sun_Frontback_Day_15771.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\val\\C_Frontback_G01_V3F_HY_1181_20160212_023749_E_CH1_Seoul_Sun_Frontback_Sunset_86619.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "WARNING \u001b[34m\u001b[1mval: \u001b[0mNo labels found in C:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\labels\\val\\C_Frontback_D02.cache. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\labels\\val\\C_Frontback_D02.cache\n",
      "WARNING Labels are missing or empty in C:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\labels\\val\\C_Frontback_D02.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to C:\\Users\\hyunj\\Downloads\\deep_test\\yolo_results\\crack_seg2\\labels.jpg... \n",
      "WARNING zero-size array to reduction operation maximum which has no identity\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n"
     ]
    },
    {
     "ename": "UnsupportedModelRegistryStoreURIException",
     "evalue": " Model registry functionality is unavailable; got unsupported URI 'e:\\runs\\mlflow' for model registry data storage. Supported URI schemes are: ['', 'file', 'databricks', 'databricks-uc', 'uc', 'http', 'https', 'postgresql', 'mysql', 'sqlite', 'mssql']. See https://www.mlflow.org/docs/latest/tracking.html#storage for how to run an MLflow server against one of the supported backend storage locations.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\mlflow\\tracking\\registry.py:81\u001b[0m, in \u001b[0;36mStoreRegistry.get_store_builder\u001b[1;34m(self, store_uri)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m     store_builder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_registry\u001b[49m\u001b[43m[\u001b[49m\u001b[43mscheme\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'e'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnsupportedModelRegistryStoreURIException\u001b[0m Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 82\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# ─── 6) YOLOv8n-seg 학습 실행 ─────────────────────────────\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# (로컬에 GPU 없으면 device=\"cpu\" 로 변경하세요)\u001b[39;00m\n\u001b[0;32m     81\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov8n-seg.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 82\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43myaml_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m# GPU가 없으면 \"cpu\" 로\u001b[39;49;00m\n\u001b[0;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcrack_seg2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBASE\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myolo_results\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_posix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ 학습 완료\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\ultralytics\\engine\\model.py:793\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m    792\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 793\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\ultralytics\\engine\\trainer.py:211\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    208\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\ultralytics\\engine\\trainer.py:332\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m world_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_ddp(world_size)\n\u001b[1;32m--> 332\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m nb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader)  \u001b[38;5;66;03m# number of batches\u001b[39;00m\n\u001b[0;32m    335\u001b[0m nw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mwarmup_epochs \u001b[38;5;241m*\u001b[39m nb), \u001b[38;5;241m100\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mwarmup_epochs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# warmup iterations\u001b[39;00m\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\ultralytics\\engine\\trainer.py:326\u001b[0m, in \u001b[0;36mBaseTrainer._setup_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_training(ckpt)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mlast_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_epoch \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# do not move\u001b[39;00m\n\u001b[1;32m--> 326\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_pretrain_routine_end\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\ultralytics\\engine\\trainer.py:173\u001b[0m, in \u001b[0;36mBaseTrainer.run_callbacks\u001b[1;34m(self, event)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run all existing callbacks associated with a particular event.\"\"\"\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mget(event, []):\n\u001b[1;32m--> 173\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\ultralytics\\utils\\callbacks\\mlflow.py:76\u001b[0m, in \u001b[0;36mon_pretrain_routine_end\u001b[1;34m(trainer)\u001b[0m\n\u001b[0;32m     74\u001b[0m experiment_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMLFLOW_EXPERIMENT_NAME\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mproject \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Shared/Ultralytics\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     75\u001b[0m run_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMLFLOW_RUN\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m---> 76\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mautolog()\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\mlflow\\tracking\\fluent.py:153\u001b[0m, in \u001b[0;36mset_experiment\u001b[1;34m(experiment_name, experiment_id)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (experiment_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m experiment_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m     experiment_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m experiment_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    147\u001b[0m ):\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m    149\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust specify exactly one of: `experiment_id` or `experiment_name`.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    150\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mINVALID_PARAMETER_VALUE,\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _experiment_lock:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m experiment_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\mlflow\\tracking\\client.py:159\u001b[0m, in \u001b[0;36mMlflowClient.__init__\u001b[1;34m(self, tracking_uri, registry_uri)\u001b[0m\n\u001b[0;32m    157\u001b[0m final_tracking_uri \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39m_resolve_tracking_uri(tracking_uri)\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registry_uri \u001b[38;5;241m=\u001b[39m registry_utils\u001b[38;5;241m.\u001b[39m_resolve_registry_uri(registry_uri, tracking_uri)\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tracking_client \u001b[38;5;241m=\u001b[39m \u001b[43mTrackingServiceClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_tracking_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:84\u001b[0m, in \u001b[0;36mTrackingServiceClient.__init__\u001b[1;34m(self, tracking_uri)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracking_uri \u001b[38;5;241m=\u001b[39m tracking_uri\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# NB: Fetch the tracking store (`self.store`) upon client initialization to ensure that\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# the tracking URI is valid and the store can be properly resolved. We define `store` as a\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# property method to ensure that the client is serializable, even if the store is not\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# self.store\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:88\u001b[0m, in \u001b[0;36mTrackingServiceClient.store\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstore\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_store\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtracking_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\utils.py:210\u001b[0m, in \u001b[0;36m_get_store\u001b[1;34m(store_uri, artifact_uri)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_store\u001b[39m(store_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, artifact_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tracking_store_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\registry.py:45\u001b[0m, in \u001b[0;36mTrackingStoreRegistry.get_store\u001b[1;34m(self, store_uri, artifact_uri)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtracking\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tracking_service\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[0;32m     44\u001b[0m resolved_store_uri \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39m_resolve_tracking_uri(store_uri)\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_store_with_resolved_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_store_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\registry.py:55\u001b[0m, in \u001b[0;36mTrackingStoreRegistry._get_store_with_resolved_uri\u001b[1;34m(self, resolved_store_uri, artifact_uri)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03mRetrieve the store associated with a resolved (non-None) store URI and an artifact URI.\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03mCaching is done on resolved URIs because the meaning of an unresolved (None) URI may change\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03mdepending on external configuration, such as environment variables\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _building_store_lock:\n\u001b[1;32m---> 55\u001b[0m     builder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_store_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolved_store_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m builder(store_uri\u001b[38;5;241m=\u001b[39mresolved_store_uri, artifact_uri\u001b[38;5;241m=\u001b[39martifact_uri)\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\mlflow\\tracking\\registry.py:83\u001b[0m, in \u001b[0;36mStoreRegistry.get_store_builder\u001b[1;34m(self, store_uri)\u001b[0m\n\u001b[0;32m     81\u001b[0m     store_builder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registry[scheme]\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m---> 83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnsupportedModelRegistryStoreURIException(\n\u001b[0;32m     84\u001b[0m         unsupported_uri\u001b[38;5;241m=\u001b[39mstore_uri, supported_uri_schemes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registry\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m     85\u001b[0m     )\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m store_builder\n",
      "\u001b[1;31mUnsupportedModelRegistryStoreURIException\u001b[0m:  Model registry functionality is unavailable; got unsupported URI 'e:\\runs\\mlflow' for model registry data storage. Supported URI schemes are: ['', 'file', 'databricks', 'databricks-uc', 'uc', 'http', 'https', 'postgresql', 'mysql', 'sqlite', 'mssql']. See https://www.mlflow.org/docs/latest/tracking.html#storage for how to run an MLflow server against one of the supported backend storage locations."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ─── 0) 설정 ────────────────────────────────────────────\n",
    "BASE        = Path(r\"C:\\Users\\hyunj\\Downloads\\deep_test\")\n",
    "IMAGE_ROOT  = BASE / \"gray\"\n",
    "LABEL_ROOT  = BASE / \"txt\"    # 세그멘테이션 .txt 라벨 폴더\n",
    "SUBFOLDERS  = [\"C_Frontback_D02\", \"C_Frontback_G01\"]\n",
    "\n",
    "# ─── 1) 출력(train/val) 폴더 준비 ──────────────────────────\n",
    "train_img_out = BASE / \"dataset\" / \"images\" / \"train\"\n",
    "train_lbl_out = BASE / \"dataset\" / \"labels\" / \"train\"\n",
    "val_img_out   = BASE / \"dataset\" / \"images\" / \"val\"\n",
    "val_lbl_out   = BASE / \"dataset\" / \"labels\" / \"val\"\n",
    "for p in (train_img_out, train_lbl_out, val_img_out, val_lbl_out):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ─── 2) (이미지, 라벨) 파일 쌍 수집 ────────────────────────\n",
    "pairs = []\n",
    "for sub in SUBFOLDERS:\n",
    "    img_dir = IMAGE_ROOT / sub\n",
    "    lbl_dir = LABEL_ROOT  / sub\n",
    "\n",
    "    # 이미지 확장자 모두\n",
    "    img_files = list(img_dir.glob(\"*.webp\")) + list(img_dir.glob(\"*.png\"))\n",
    "    for img_path in img_files:\n",
    "        stem = img_path.stem\n",
    "        # 라벨 후보 두 가지\n",
    "        candidates = [\n",
    "            lbl_dir / f\"{stem}.txt\",\n",
    "            lbl_dir / f\"{stem}_mask.txt\"\n",
    "        ]\n",
    "        # 존재하는 첫 번째 라벨 사용\n",
    "        txt_path = next((p for p in candidates if p.exists()), None)\n",
    "        if txt_path:\n",
    "            pairs.append((img_path, txt_path))\n",
    "        else:\n",
    "            print(f\"[누락] 라벨 없음: {img_path.name} -> {candidates}\")\n",
    "\n",
    "print(f\"✅ 전체 파일 쌍: {len(pairs)}\")\n",
    "\n",
    "# ─── 3) train/val 분할 (80/20) ─────────────────────────────\n",
    "random.seed(30)\n",
    "random.shuffle(pairs)\n",
    "split_idx   = int(len(pairs) * 0.8)\n",
    "train_pairs = pairs[:split_idx]\n",
    "val_pairs   = pairs[split_idx:]\n",
    "print(f\"train: {len(train_pairs)} 쌍, val: {len(val_pairs)} 쌍\")\n",
    "\n",
    "# ─── 4) 파일 복사 ─────────────────────────────────────────\n",
    "def copy_pairs(pairs, img_out, lbl_out):\n",
    "    for img_path, txt_path in pairs:\n",
    "        # sub폴더명_원본이름 으로 파일명 충돌 방지\n",
    "        new_img = f\"{img_path.parent.name}_{img_path.name}\"\n",
    "        new_lbl = f\"{txt_path.parent.name}_{txt_path.name}\"\n",
    "        shutil.copy2(img_path, img_out / new_img)\n",
    "        shutil.copy2(txt_path, lbl_out / new_lbl)\n",
    "\n",
    "copy_pairs(train_pairs, train_img_out, train_lbl_out)\n",
    "copy_pairs(val_pairs,   val_img_out,   val_lbl_out)\n",
    "print(\"✅ train/val 파일 복사 완료\")\n",
    "\n",
    "# ─── 5) data.yaml 생성 ────────────────────────────────────\n",
    "data_yaml = {\n",
    "    \"train\": str((BASE/\"dataset\"/\"images\"/\"train\").as_posix()),\n",
    "    \"val\":   str((BASE/\"dataset\"/\"images\"/\"val\").as_posix()),\n",
    "    \"nc\":    1,\n",
    "    \"names\": [\"crack\"]\n",
    "}\n",
    "yaml_path = BASE / \"crack_segmentation2.yaml\"\n",
    "with open(yaml_path, \"w\") as f:\n",
    "    yaml.dump(data_yaml, f, sort_keys=False)\n",
    "print(f\"✅ data.yaml 생성: {yaml_path}\")\n",
    "\n",
    "# ─── 6) YOLOv8n-seg 학습 실행 ─────────────────────────────\n",
    "# (로컬에 GPU 없으면 device=\"cpu\" 로 변경하세요)\n",
    "model = YOLO(\"yolov8n-seg.pt\")\n",
    "model.train(\n",
    "    data=str(yaml_path).replace(\"\\\\\", \"/\"),\n",
    "    imgsz=640,\n",
    "    epochs=50,\n",
    "    batch=8,\n",
    "    device=\"cpu\",                    # GPU가 없으면 \"cpu\" 로\n",
    "    name=\"crack_seg2\",\n",
    "    project=str((BASE/\"yolo_results\").as_posix())\n",
    ")\n",
    "print(\"✅ 학습 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f624309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.145 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.137  Python-3.9.21 torch-2.7.0+cu128 CPU (11th Gen Intel Core(TM) i7-11700 2.50GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:/Users/hyunj/Downloads/deep_test/crack_segmentation2.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=crack_seg24, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:/Users/hyunj/Downloads/deep_test/yolo_results, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\hyunj\\Downloads\\deep_test\\yolo_results\\crack_seg24, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   1004275  ultralytics.nn.modules.head.Segment          [1, 32, 64, [64, 128, 256]]   \n",
      "YOLOv8n-seg summary: 151 layers, 3,263,811 parameters, 3,263,795 gradients, 12.1 GFLOPs\n",
      "\n",
      "Transferred 381/417 items from pretrained weights\n",
      "WARNING ClearML installed but not initialized correctly, not logging this run. It seems ClearML is not configured on this machine!\n",
      "To get started with ClearML, setup your own 'clearml-server' or create a free account at https://app.clear.ml\n",
      "Setup instructions can be found here: https://clear.ml/docs\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 521.1130.0 MB/s, size: 148.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\labels\\train\\C_Frontback_D02.cache... 0 images, 28529 backgrounds, 31 corrupt: 100%|██████████| 28560/28560 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_0898_20201231_111555_E_CH0_Seoul_Sun_Frontback_Day_88937.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_2899_20201109_093348_N_CH2_Seoul_Sun_Frontback_Day_04037.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_4471_20201230_122847_E_CH0_Seoul_Sun_Frontback_Day_83952.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_5502_20201224_104609_N_CH1_Seoul_Sun_Frontback_Sunrise_40987.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_6015_20201109_094048_N_CH2_Seoul_Sun_Frontback_Day_59877.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_6054_20201231_111555_E_CH1_Seoul_Sun_Frontback_Day_64387.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_6428_20201109_093048_E_CH0_Seoul_Sun_Frontback_Day_80356.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_7516_20201229_171815_N_CH0_Seoul_Sun_Frontback_Sunset_95390.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_7636_20201109_093348_E_CH2_Seoul_Sun_Frontback_Day_99127.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_9158_20201102_113908_E_CH0_Seoul_Sun_Frontback_Day_55738.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_9601_20201109_093348_E_CH1_Seoul_Sun_Frontback_Day_81018.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_9694_20201109_093848_N_CH0_Seoul_Sun_Frontback_Day_15771.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V3F_HY_0637_20201102_134232_E_CH0_Seoul_Sun_Frontback_Day_90729.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V3F_HY_1050_20201102_134032_E_CH1_Seoul_Sun_Frontback_Day_69335.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V3F_HY_5009_20160212_023050_N_CH1_Seoul_Sun_Frontback_Day_33344.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_0898_20201231_111555_E_CH0_Seoul_Sun_Frontback_Day_88937.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_2899_20201109_093348_N_CH2_Seoul_Sun_Frontback_Day_04037.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_3674_20201230_150636_N_CH0_Seoul_Sun_Frontback_Day_74627.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_4471_20201230_122847_E_CH0_Seoul_Sun_Frontback_Day_83952.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_5502_20201224_104609_N_CH1_Seoul_Sun_Frontback_Sunrise_40987.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_6015_20201109_094048_N_CH2_Seoul_Sun_Frontback_Day_59877.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_6054_20201231_111555_E_CH1_Seoul_Sun_Frontback_Day_64387.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_7516_20201229_171815_N_CH0_Seoul_Sun_Frontback_Sunset_95390.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_7636_20201109_093348_E_CH2_Seoul_Sun_Frontback_Day_99127.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_8030_20201231_111555_E_CH0_Seoul_Sun_Frontback_Day_86195.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_9158_20201102_113908_E_CH0_Seoul_Sun_Frontback_Day_55738.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_9601_20201109_093348_E_CH1_Seoul_Sun_Frontback_Day_81018.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V3F_HY_0637_20201102_134232_E_CH0_Seoul_Sun_Frontback_Day_90729.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V3F_HY_1050_20201102_134032_E_CH1_Seoul_Sun_Frontback_Day_69335.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V3F_HY_1347_20160212_022303_N_CH0_Seoul_Sun_Frontback_Day_76884.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V3F_HY_5009_20160212_023050_N_CH1_Seoul_Sun_Frontback_Day_33344.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "WARNING Labels are missing or empty in C:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\labels\\train\\C_Frontback_D02.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 1078.0279.4 MB/s, size: 149.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\labels\\val\\C_Frontback_D02.cache... 0 images, 7135 backgrounds, 7 corrupt: 100%|██████████| 7142/7142 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\val\\C_Frontback_G01\\V2F_HY_3674_20201230_150636_N_CH0_Seoul_Sun_Frontback_Day_74627.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\val\\C_Frontback_G01\\V2F_HY_8030_20201231_111555_E_CH0_Seoul_Sun_Frontback_Day_86195.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\val\\C_Frontback_G01\\V3F_HY_1181_20160212_023749_E_CH1_Seoul_Sun_Frontback_Sunset_86619.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\val\\C_Frontback_G01\\V3F_HY_1347_20160212_022303_N_CH0_Seoul_Sun_Frontback_Day_76884.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\val\\C_Frontback_G01_V2F_HY_6428_20201109_093048_E_CH0_Seoul_Sun_Frontback_Day_80356.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\val\\C_Frontback_G01_V2F_HY_9694_20201109_093848_N_CH0_Seoul_Sun_Frontback_Day_15771.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\val\\C_Frontback_G01_V3F_HY_1181_20160212_023749_E_CH1_Seoul_Sun_Frontback_Sunset_86619.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "WARNING Labels are missing or empty in C:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\labels\\val\\C_Frontback_D02.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "Plotting labels to C:\\Users\\hyunj\\Downloads\\deep_test\\yolo_results\\crack_seg24\\labels.jpg... \n",
      "WARNING zero-size array to reduction operation maximum which has no identity\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "2025/05/26 20:23:28 INFO mlflow.tracking.fluent: Experiment with name 'C:/Users/hyunj/Downloads/deep_test/yolo_results' does not exist. Creating a new experiment.\n",
      "2025/05/26 20:23:28 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
      "2025/05/26 20:23:28 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mMLflow: \u001b[0mlogging run_id(b35d8c6972534cf297d56c2f720fea3d) to file:///C:/Users/hyunj/Downloads/deep_test/mlruns\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\hyunj\\Downloads\\deep_test\\yolo_results\\crack_seg24\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50         0G          0          0      3.121          0          0        640: 100%|██████████| 3567/3567 [4:29:26<00:00,  4.53s/it]  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 446/446 [09:58<00:00,  1.34s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "torch.cat(): expected a non-empty list of Tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 3) 학습 실행\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:/Users/hyunj/Downloads/deep_test/crack_segmentation2.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcrack_seg2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:/Users/hyunj/Downloads/deep_test/yolo_results\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     26\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\ultralytics\\engine\\model.py:793\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m    792\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 793\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\ultralytics\\engine\\trainer.py:211\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    208\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\ultralytics\\engine\\trainer.py:443\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;66;03m# Validation\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mval \u001b[38;5;129;01mor\u001b[39;00m final_epoch \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopper\u001b[38;5;241m.\u001b[39mpossible_stop \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop:\n\u001b[1;32m--> 443\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_metrics(metrics\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_loss_items(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr})\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopper(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness) \u001b[38;5;129;01mor\u001b[39;00m final_epoch\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\ultralytics\\engine\\trainer.py:639\u001b[0m, in \u001b[0;36mBaseTrainer.validate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    633\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;124;03m    Run validation on test set using self.validator.\u001b[39;00m\n\u001b[0;32m    635\u001b[0m \n\u001b[0;32m    636\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;124;03m        (tuple): A tuple containing metrics dictionary and fitness score.\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 639\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    640\u001b[0m     fitness \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())  \u001b[38;5;66;03m# use loss as fitness measure if not found\u001b[39;00m\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_fitness \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_fitness \u001b[38;5;241m<\u001b[39m fitness:\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\ultralytics\\engine\\validator.py:231\u001b[0m, in \u001b[0;36mBaseValidator.__call__\u001b[1;34m(self, trainer, model)\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_predictions(batch, preds, batch_i)\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_val_batch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 231\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_stats(stats)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspeed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspeed\u001b[38;5;241m.\u001b[39mkeys(), (x\u001b[38;5;241m.\u001b[39mt \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader\u001b[38;5;241m.\u001b[39mdataset) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1e3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m dt)))\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\ultralytics\\models\\yolo\\detect\\val.py:247\u001b[0m, in \u001b[0;36mDetectionValidator.get_stats\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_stats\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    241\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03m    Calculate and return metrics statistics.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m        (dict): Dictionary containing metrics results.\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m     stats \u001b[38;5;241m=\u001b[39m {k: torch\u001b[38;5;241m.\u001b[39mcat(v, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mitems()}  \u001b[38;5;66;03m# to numpy\u001b[39;00m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnt_per_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_cls\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m), minlength\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnc)\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnt_per_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_img\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m), minlength\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnc)\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\ultralytics\\models\\yolo\\detect\\val.py:247\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_stats\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    241\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03m    Calculate and return metrics statistics.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m        (dict): Dictionary containing metrics results.\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m     stats \u001b[38;5;241m=\u001b[39m {k: \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mitems()}  \u001b[38;5;66;03m# to numpy\u001b[39;00m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnt_per_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_cls\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m), minlength\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnc)\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnt_per_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_img\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m), minlength\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnc)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: torch.cat(): expected a non-empty list of Tensors"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 0) MLflow 로깅 & 레지스트리 전부 로컬 파일로 리다이렉트\n",
    "mlruns = r\"C:\\Users\\hyunj\\Downloads\\deep_test\\mlruns\"\n",
    "os.makedirs(mlruns, exist_ok=True)\n",
    "file_uri = f\"file:///{mlruns.replace(os.sep, '/')}\"\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = file_uri\n",
    "os.environ[\"MLFLOW_REGISTRY_URI\"] = file_uri\n",
    "\n",
    "# 1) 모델 로드\n",
    "model = YOLO(\"yolov8n-seg.pt\")\n",
    "\n",
    "# 2) (Optional) 모든 콜백 제거 — 여기까진 이제 에러 없을 겁니다\n",
    "model.callbacks = []\n",
    "\n",
    "# 3) 학습 실행\n",
    "model.train(\n",
    "    data=\"C:/Users/hyunj/Downloads/deep_test/crack_segmentation2.yaml\",\n",
    "    imgsz=640,\n",
    "    epochs=50,\n",
    "    batch=8,\n",
    "    device=\"cpu\",  \n",
    "    name=\"crack_seg2\",\n",
    "    project=\"C:/Users/hyunj/Downloads/deep_test/yolo_results\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6121b1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.145 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.137  Python-3.9.21 torch-2.7.0+cu128 CPU (11th Gen Intel Core(TM) i7-11700 2.50GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:/Users/hyunj/Downloads/deep_test/crack_segmentation2.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=crack_seg28, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:/Users/hyunj/Downloads/deep_test/yolo_results, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\hyunj\\Downloads\\deep_test\\yolo_results\\crack_seg28, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=False, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   1004275  ultralytics.nn.modules.head.Segment          [1, 32, 64, [64, 128, 256]]   \n",
      "YOLOv8n-seg summary: 151 layers, 3,263,811 parameters, 3,263,795 gradients, 12.1 GFLOPs\n",
      "\n",
      "Transferred 381/417 items from pretrained weights\n",
      "WARNING ClearML installed but not initialized correctly, not logging this run. It seems ClearML is not configured on this machine!\n",
      "To get started with ClearML, setup your own 'clearml-server' or create a free account at https://app.clear.ml\n",
      "Setup instructions can be found here: https://clear.ml/docs\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 659.9120.0 MB/s, size: 148.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\labels\\train\\C_Frontback_D02.cache... 0 images, 28529 backgrounds, 31 corrupt: 100%|██████████| 28560/28560 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_0898_20201231_111555_E_CH0_Seoul_Sun_Frontback_Day_88937.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_2899_20201109_093348_N_CH2_Seoul_Sun_Frontback_Day_04037.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_4471_20201230_122847_E_CH0_Seoul_Sun_Frontback_Day_83952.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_5502_20201224_104609_N_CH1_Seoul_Sun_Frontback_Sunrise_40987.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_6015_20201109_094048_N_CH2_Seoul_Sun_Frontback_Day_59877.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_6054_20201231_111555_E_CH1_Seoul_Sun_Frontback_Day_64387.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_6428_20201109_093048_E_CH0_Seoul_Sun_Frontback_Day_80356.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_7516_20201229_171815_N_CH0_Seoul_Sun_Frontback_Sunset_95390.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_7636_20201109_093348_E_CH2_Seoul_Sun_Frontback_Day_99127.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_9158_20201102_113908_E_CH0_Seoul_Sun_Frontback_Day_55738.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_9601_20201109_093348_E_CH1_Seoul_Sun_Frontback_Day_81018.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V2F_HY_9694_20201109_093848_N_CH0_Seoul_Sun_Frontback_Day_15771.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V3F_HY_0637_20201102_134232_E_CH0_Seoul_Sun_Frontback_Day_90729.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V3F_HY_1050_20201102_134032_E_CH1_Seoul_Sun_Frontback_Day_69335.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01\\V3F_HY_5009_20160212_023050_N_CH1_Seoul_Sun_Frontback_Day_33344.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_0898_20201231_111555_E_CH0_Seoul_Sun_Frontback_Day_88937.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_2899_20201109_093348_N_CH2_Seoul_Sun_Frontback_Day_04037.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_3674_20201230_150636_N_CH0_Seoul_Sun_Frontback_Day_74627.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_4471_20201230_122847_E_CH0_Seoul_Sun_Frontback_Day_83952.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_5502_20201224_104609_N_CH1_Seoul_Sun_Frontback_Sunrise_40987.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_6015_20201109_094048_N_CH2_Seoul_Sun_Frontback_Day_59877.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_6054_20201231_111555_E_CH1_Seoul_Sun_Frontback_Day_64387.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_7516_20201229_171815_N_CH0_Seoul_Sun_Frontback_Sunset_95390.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_7636_20201109_093348_E_CH2_Seoul_Sun_Frontback_Day_99127.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_8030_20201231_111555_E_CH0_Seoul_Sun_Frontback_Day_86195.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_9158_20201102_113908_E_CH0_Seoul_Sun_Frontback_Day_55738.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V2F_HY_9601_20201109_093348_E_CH1_Seoul_Sun_Frontback_Day_81018.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V3F_HY_0637_20201102_134232_E_CH0_Seoul_Sun_Frontback_Day_90729.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V3F_HY_1050_20201102_134032_E_CH1_Seoul_Sun_Frontback_Day_69335.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V3F_HY_1347_20160212_022303_N_CH0_Seoul_Sun_Frontback_Day_76884.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\train\\C_Frontback_G01_V3F_HY_5009_20160212_023050_N_CH1_Seoul_Sun_Frontback_Day_33344.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING Labels are missing or empty in C:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\labels\\train\\C_Frontback_D02.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 588.4125.6 MB/s, size: 149.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\labels\\val\\C_Frontback_D02.cache... 0 images, 7135 backgrounds, 7 corrupt: 100%|██████████| 7142/7142 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\val\\C_Frontback_G01\\V2F_HY_3674_20201230_150636_N_CH0_Seoul_Sun_Frontback_Day_74627.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\val\\C_Frontback_G01\\V2F_HY_8030_20201231_111555_E_CH0_Seoul_Sun_Frontback_Day_86195.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\val\\C_Frontback_G01\\V3F_HY_1181_20160212_023749_E_CH1_Seoul_Sun_Frontback_Sunset_86619.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\val\\C_Frontback_G01\\V3F_HY_1347_20160212_022303_N_CH0_Seoul_Sun_Frontback_Day_76884.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\val\\C_Frontback_G01_V2F_HY_6428_20201109_093048_E_CH0_Seoul_Sun_Frontback_Day_80356.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\val\\C_Frontback_G01_V2F_HY_9694_20201109_093848_N_CH0_Seoul_Sun_Frontback_Day_15771.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\images\\val\\C_Frontback_G01_V3F_HY_1181_20160212_023749_E_CH1_Seoul_Sun_Frontback_Sunset_86619.webp: ignoring corrupt image/label: image size (1, 1) <10 pixels\n",
      "WARNING Labels are missing or empty in C:\\Users\\hyunj\\Downloads\\deep_test\\dataset\\labels\\val\\C_Frontback_D02.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "e:\\Anaconda\\envs\\igpu39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to C:\\Users\\hyunj\\Downloads\\deep_test\\yolo_results\\crack_seg28\\labels.jpg... \n",
      "WARNING zero-size array to reduction operation maximum which has no identity\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/27 01:49:09 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
      "2025/05/27 01:49:09 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mMLflow: \u001b[0mlogging run_id(b35d8c6972534cf297d56c2f720fea3d) to file:///C:/Users/hyunj/Downloads/deep_test/mlruns\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n",
      "WARNING \u001b[34m\u001b[1mMLflow: \u001b[0mFailed to initialize: Changing param values is not allowed. Param with key='name' was already logged with value='crack_seg24' for run ID='b35d8c6972534cf297d56c2f720fea3d'. Attempted logging new value 'crack_seg28'.\n",
      "WARNING \u001b[34m\u001b[1mMLflow: \u001b[0mNot tracking this run\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\hyunj\\Downloads\\deep_test\\yolo_results\\crack_seg28\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50         0G          0          0      3.121          0          0        640: 100%|██████████| 3567/3567 [2:35:37<00:00,  2.62s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50         0G          0          0  3.837e-08          0          0        640: 100%|██████████| 3567/3567 [2:32:07<00:00,  2.56s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50         0G          0          0          0          0          0        640: 100%|██████████| 3567/3567 [2:28:34<00:00,  2.50s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       4/50         0G          0          0          0          0          0        640: 100%|██████████| 3567/3567 [2:28:01<00:00,  2.49s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50         0G          0          0          0          0          0        640: 100%|██████████| 3567/3567 [2:38:41<00:00,  2.67s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50         0G          0          0          0          0          0        640: 100%|██████████| 3567/3567 [3:04:08<00:00,  3.10s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50         0G          0          0          0          0          0        640: 100%|██████████| 3567/3567 [2:56:07<00:00,  2.96s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50         0G          0          0          0          0          0        640:  83%|████████▎ | 2962/3567 [2:22:25<29:15,  2.90s/it]  "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n-seg.pt\")\n",
    "model.train(\n",
    "    data=\"C:/Users/hyunj/Downloads/deep_test/crack_segmentation2.yaml\",\n",
    "    imgsz=640,\n",
    "    epochs=50,\n",
    "    batch=8,\n",
    "    device=\"cpu\",  \n",
    "    name=\"crack_seg2\",\n",
    "    project=\"C:/Users/hyunj/Downloads/deep_test/yolo_results\",\n",
    "    val=False   # ← 검증 스킵\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281a4514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(r\"C:\\Users\\hyunj\\Downloads\\deep_test\")\n",
    "\n",
    "cmd = (\n",
    "    \"yolo train \"\n",
    "    \"model=yolov8n-seg.pt \"\n",
    "    \"data=data.yaml \"\n",
    "    \"epochs=50 \"\n",
    "    \"imgsz=640 \"\n",
    "    \"batch=8 \"\n",
    "    \"name=crack_segmentation\"\n",
    ")\n",
    "os.system(cmd)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py39 (XPU)",
   "language": "python",
   "name": "igpu39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
